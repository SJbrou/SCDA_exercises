[
  {
    "objectID": "tutorial1.html",
    "href": "tutorial1.html",
    "title": "Tutorial week 1",
    "section": "",
    "text": "Exercise 1",
    "crumbs": [
      "Tutorials",
      "Tutorial 1"
    ]
  },
  {
    "objectID": "tutorial1.html#section",
    "href": "tutorial1.html#section",
    "title": "Tutorial week 1",
    "section": "1.1",
    "text": "1.1\nVisualize the time series for the entire duration\n\n\nCode\n# Load the data\nsupermarket_data &lt;- read_excel(\"data/SupermarketSales.xlsx\")\n\n# plot the timeseries\nplot.ts(supermarket_data$demand)",
    "crumbs": [
      "Tutorials",
      "Tutorial 1"
    ]
  },
  {
    "objectID": "tutorial1.html#section-1",
    "href": "tutorial1.html#section-1",
    "title": "Tutorial week 1",
    "section": "1.2",
    "text": "1.2\nPrepare and clean the data as necessary to ensure accuracy for analysis.\na few notes: - there are a few missing observation dates (missing data) - there are negative values. Lets suppose they should be removed. - there are outliers, lets remove those as well\nNow we end up with much missing (“NA”) data. We should also curve-fit them\n\n\nCode\n# lets start by converting dates to a machine-readable date format\nsupermarket_data &lt;- supermarket_data %&gt;%\n  mutate(date = as.Date(as.character(date), format = \"%Y%m%d\"))\n\n# Now lets create a sequence of dates with the missing dates\nall_dates &lt;- data.frame(date = seq(min(supermarket_data$date), max(supermarket_data$date), by = \"day\"))\n\n# Join the two dataframes and introduce \"NA\" values on missing dates\ndata &lt;- all_dates %&gt;%\n  left_join(supermarket_data, by = \"date\")\n\n# Change any negative value to \"NA\"\ndata &lt;- data %&gt;%\n  mutate(demand = ifelse(demand &lt; 0, NA, demand))\n\nplot_ly(data, x = ~date, y = ~demand, type = 'scatter', mode = 'lines') # nice interactive plot",
    "crumbs": [
      "Tutorials",
      "Tutorial 1"
    ]
  },
  {
    "objectID": "tutorial1.html#section-2",
    "href": "tutorial1.html#section-2",
    "title": "Tutorial week 1",
    "section": "1.3",
    "text": "1.3\nSplit the data into training and validation sets. What proportion of the data would be reasonable for each set based on the characteristics of the time series?\n**In class a default of 80/20 or 70/30 was discussed. As there are 4 distinct periods, the last one could be used as validation set. (however, the demand in 2021 seems particularly weak!)\n§",
    "crumbs": [
      "Tutorials",
      "Tutorial 1"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Supply Chain Data Analytics",
    "section": "",
    "text": "Home\nThese are my resources for the Supply Chain Data Analytics course. I like ordering these so I can order my thoughts. Hopefully you’ll find in them as well\nThe site is hosted on github pages and written and build using Rstudio and Quarto. You can always reach out to me if you want to chat about hosting your own sites on github. I’m available.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "assignment1.html",
    "href": "assignment1.html",
    "title": "Assignment 1",
    "section": "",
    "text": "Data selection\nWe selected the EU superstore sales data provided by tableau\nIt has~10k sales (of differing quantities), divided over ~1k unique product_names. The product’s category and sub-category are also provided\nBefore getting started, lets clear the workspace and load any dependencies.\nCode\n# Clear workspace\nrm(list = ls())\n\n# Method for loading dependencies\ninstall_and_load &lt;- function(packages) {\n  installed_packages &lt;- rownames(installed.packages())                                # Check installed packages\n  to_install &lt;- packages[!(packages %in% installed_packages)]\n  if (length(to_install) &gt; 0) {install.packages(to_install, dependencies = TRUE)}     # Install missing packages\n  suppressMessages(lapply(packages, require, character.only = TRUE, quietly = TRUE))} # Load packages\ninstall_and_load(c(\"tidyverse\", \"readxl\", \"ggplot2\", \"plotly\", \"dplyr\", \"lubridate\", \"gt\", \"stats\")) # Method call with list of package names\n\n\nWarning: package 'gt' was built under R version 4.3.3",
    "crumbs": [
      "Assignments",
      "Assignment 1"
    ]
  },
  {
    "objectID": "usefull_functions.html",
    "href": "usefull_functions.html",
    "title": "1  Usefull functions",
    "section": "",
    "text": "Task\nFunction\n\n\n\n\nSimple exponential smoothing\nses(data, alpha, h)\n\n\nHolt’s model\nholt(data, alpha, beta, h) –&gt; Only for additive error and addititve trend\n\n\nHolt-Winter’s model\nhw(data, seasonal, trend, alpha, beta, gamma, h)\nOnly for additive error\nAny exponential smoothing\n\n\nAny exponential smoothing\nets(data, model=“ZAA” or any other combination\nIf you do not specify model and parameters, ets() selects the best smoothing model and best parameters\n\n\ncentered moving average\nrollmean(data, window size, align=“center”)\n\n\ntrailed moving average\nrollmean(data, window size, align=“right”)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>usefull functions</span>"
    ]
  },
  {
    "objectID": "assignment1.html#data-pre-processing",
    "href": "assignment1.html#data-pre-processing",
    "title": "Assignment 1",
    "section": "Data Pre-processing:",
    "text": "Data Pre-processing:\nLets load and transform the data correctly so it can be used\nLets start by loading the data, converting dates to a machine-readable format and checking for missing values:\n\n\nCode\n# Load the data\nsuppressWarnings({data &lt;- read_excel(\"data/assignment1/sample_-_superstore.xls\")})\n# Note here that loading the data itself can give some warnings, which we supress. Probably due to excel having weird date-time formats that always cause frictions. \n\n# Ensure machine-readable date-time format\ndata$`Order Date` &lt;- as.Date(data$`Order Date`, format = \"%Y-%m-%d\")\n\n# Check for missing values in each column\nmissing_values &lt;- colSums(is.na(data))\nmissing_values # Note, there are none.\n\n\n       Row ID      Order ID    Order Date     Ship Date     Ship Mode \n            0             0             0             0             0 \n  Customer ID Customer Name       Segment       Country          City \n            0             0             0             0             0 \n        State   Postal Code        Region    Product ID      Category \n            0             0             0             0             0 \n Sub-Category  Product Name         Sales      Quantity      Discount \n            0             0             0             0             0 \n       Profit \n            0 \n\n\nCode\n# table of first 5 rows\ndata %&gt;%\n  head(5) %&gt;%\n  gt() %&gt;%\n  tab_header(\n    title = \"Superstore Sample - First 5 Rows\"\n  ) %&gt;%\n  cols_align(\n    align = \"center\"\n  ) %&gt;%\n  fmt_date(\n    columns = vars(`Order Date`),\n    date_style = 3  # date format as %month %d, $yyyy\n  )\n\n\nWarning: Since gt v0.3.0, `columns = vars(...)` has been deprecated.\n• Please use `columns = c(...)` instead.\n\n\n\n\n\n\n\n\nSuperstore Sample - First 5 Rows\n\n\nRow ID\nOrder ID\nOrder Date\nShip Date\nShip Mode\nCustomer ID\nCustomer Name\nSegment\nCountry\nCity\nState\nPostal Code\nRegion\nProduct ID\nCategory\nSub-Category\nProduct Name\nSales\nQuantity\nDiscount\nProfit\n\n\n\n\n1\nCA-2016-152156\nTue, Nov 8, 2016\n2016-11-11\nSecond Class\nCG-12520\nClaire Gute\nConsumer\nUnited States\nHenderson\nKentucky\n42420\nSouth\nFUR-BO-10001798\nFurniture\nBookcases\nBush Somerset Collection Bookcase\n261.9600\n2\n0.00\n41.9136\n\n\n2\nCA-2016-152156\nTue, Nov 8, 2016\n2016-11-11\nSecond Class\nCG-12520\nClaire Gute\nConsumer\nUnited States\nHenderson\nKentucky\n42420\nSouth\nFUR-CH-10000454\nFurniture\nChairs\nHon Deluxe Fabric Upholstered Stacking Chairs, Rounded Back\n731.9400\n3\n0.00\n219.5820\n\n\n3\nCA-2016-138688\nSun, Jun 12, 2016\n2016-06-16\nSecond Class\nDV-13045\nDarrin Van Huff\nCorporate\nUnited States\nLos Angeles\nCalifornia\n90036\nWest\nOFF-LA-10000240\nOffice Supplies\nLabels\nSelf-Adhesive Address Labels for Typewriters by Universal\n14.6200\n2\n0.00\n6.8714\n\n\n4\nUS-2015-108966\nSun, Oct 11, 2015\n2015-10-18\nStandard Class\nSO-20335\nSean O'Donnell\nConsumer\nUnited States\nFort Lauderdale\nFlorida\n33311\nSouth\nFUR-TA-10000577\nFurniture\nTables\nBretford CR4500 Series Slim Rectangular Table\n957.5775\n5\n0.45\n-383.0310\n\n\n5\nUS-2015-108966\nSun, Oct 11, 2015\n2015-10-18\nStandard Class\nSO-20335\nSean O'Donnell\nConsumer\nUnited States\nFort Lauderdale\nFlorida\n33311\nSouth\nOFF-ST-10000760\nOffice Supplies\nStorage\nEldon Fold 'N Roll Cart System\n22.3680\n2\n0.20\n2.5164\n\n\n\n\n\n\n\nthis looks great. Lets start visualization so we can see outliers, and decide if more data cleaning is required.",
    "crumbs": [
      "Assignments",
      "Assignment 1"
    ]
  },
  {
    "objectID": "assignment1.html#data-visualization",
    "href": "assignment1.html#data-visualization",
    "title": "Assignment 1",
    "section": "Data visualization",
    "text": "Data visualization\nLets start by aggregating the sales per product category per month and plot the top 10 most sold products\n\n\nCode\n# Sum of Quantity for top products\ntop_products &lt;- data %&gt;%\n  group_by(`Product Name`) %&gt;%\n  summarize(total_quantity = sum(Quantity, na.rm = TRUE)) %&gt;%\n  arrange(desc(total_quantity)) %&gt;%\n  top_n(20, total_quantity) %&gt;%  # Top x products\n  mutate(ProdName8 = substr(`Product Name`, 1, 8)) # Product names can be quite long and mess up layouts. Lets only plot the first 8 chars. \n\n# Plot with ggplot and ggplotly\nplot &lt;- ggplot(top_products, aes(x = reorder(ProdName8, -total_quantity), y = total_quantity)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  labs(title = \"Top 20 Most Sold Products\",\n       x = \"Product ID\",\n       y = \"Total Quantity\") +\n  theme_minimal() +\n  coord_flip()\n\n# Make the plot interactive\nggplotly(plot)\n\n\n\n\n\n\n\n\nCode\n# Aggregate quantity by Product Name and Order Date to create a time series\ntime_series_data &lt;- data %&gt;%\n  group_by(`Product Name`, `Order Date`) %&gt;%\n  summarize(total_quantity = sum(Quantity, na.rm = TRUE)) %&gt;%\n  ungroup()\n\n\n`summarise()` has grouped output by 'Product Name'. You can override using the\n`.groups` argument.\n\n\nCode\n# Filter for the top products by total quantity sold (adjust as needed)\ntop_products &lt;- time_series_data %&gt;%\n  group_by(`Product Name`) %&gt;%\n  summarize(total_quantity = sum(total_quantity)) %&gt;%\n  arrange(desc(total_quantity)) %&gt;%\n  slice_head(n = 10)  # Select top 10 products\n\n# Filter the time-series data for only these top products\nfiltered_time_series_data &lt;- time_series_data %&gt;%\n  filter(`Product Name` %in% top_products$`Product Name`) %&gt;%\n  mutate(ProdName8 = substr(`Product Name`, 1, 8)) # Product names can be quite long and mess up layouts. Lets only plot the first 8 chars. \n\n\n# Plot using the truncated product name\nplot &lt;- ggplot(filtered_time_series_data, aes(x = `Order Date`, y = total_quantity, color = ProdName8)) +\n  geom_line(size = 1) +\n  labs(title = \"Quantity Sold Over Time per Product\",\n       x = \"Order Date\",\n       y = \"Quantity Sold\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\") +\n  scale_color_discrete(name = \"Product Name\")\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nCode\n# Make the plot interactive\nggplotly(plot)\n\n\n\n\n\n\nLets also plot the frequency of 20 most sold items\n\n\nCode\n# Count frequency of top 20 products\ntop_products &lt;- data %&gt;%\n  count(`Product Name`, sort = TRUE) %&gt;%\n  top_n(20, n) %&gt;%\n  mutate(ProdName8 = substr(`Product Name`, 1, 8))\n\n# Plot!\nggplotly(ggplot(top_products, aes(x = reorder(`ProdName8`, -n), y = n)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  labs(title = \"Top 20 Most Sold Products\",\n       x = \"Product Name\",\n       y = \"Frequency\") +\n  theme_minimal() +\n  coord_flip())\n\n\n\n\n\n\nUnfortunately, these sales levels are too little to do meaningfull forecasting with. However, we can work with the sales aggregated on sub-category level. Lets visualise that data\n\n\nCode\n# Count frequency of top 20 products\ntop_categories &lt;- data %&gt;%\n  count(`Sub-Category`, sort = TRUE)\n\n# Plot!\nggplotly(ggplot(top_categories, aes(x = reorder(`Sub-Category`, -n), y = n)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  labs(title = \"Sub-Categories sorted\",\n       x = \"Product Name\",\n       y = \"Frequency\") +\n  theme_minimal() +\n  coord_flip())\n\n\n\n\n\n\nAlso, lets include time-series for the top 10 sold sub-categories:\n\n\nCode\n# Find top 3 most sold product names\ntop_3_categories &lt;- top_categories$`Sub-Category`[0:9]\n\n# Filter the data for  top 3 products\ntop_3_data &lt;- data %&gt;% filter(`Sub-Category` %in% top_3_categories)\n\n# calculate sales per month\ntop_3_data &lt;- top_3_data %&gt;%\n  mutate(Month = floor_date(`Order Date`, unit = \"month\"))\n\n# Aggregate data by month for each product\ntop_3_data_aggregated &lt;- top_3_data %&gt;%\n  group_by(Month, `Sub-Category`) %&gt;%\n  summarise(Sales_Count = n(), .groups = 'drop')\n\n# Plot!\nggplotly(\n  ggplot(top_3_data_aggregated, aes(x = Month, y = Sales_Count, color = `Sub-Category`, group = `Sub-Category`)) +\n    geom_line(size = 1) +\n    geom_point(size = 2) +  # Optional: adds points to make each data point clearer\n    labs(title = \"Monthly Sales for the Top 3 Most Sold Products\",\n         x = \"Month\",\n         y = \"Sales Count\",\n         color = \"Product Name\") +\n    theme_minimal()\n)\n\n\n\n\n\n\n\nShould there be any more visualizations?\nHaven’t looked at outliers / NA values etc\n(because I quickly assumed high-quality data due to source)\no Data visualization is essential for understanding the data before applying any forecasting methods. Using different tools, plots and charts, you will explore trends, seasonality, and any unusual patterns within your time series dataset.",
    "crumbs": [
      "Assignments",
      "Assignment 1"
    ]
  },
  {
    "objectID": "tutorial2.html",
    "href": "tutorial2.html",
    "title": "Tutorial week 2",
    "section": "",
    "text": "Example\nThe file ApplianceShipments.xls contains data on the quarterly shipments of appliances over a 5 year period\nAs provided on canvas:\nCode\nlibrary(zoo)\nlibrary(forecast)\nlibrary(TTR)\n\n#import data from CSV\nAS &lt;- read.csv(\"data/tutorial2/ApplianceShipments.csv\")\n\n#convert data to a time series object\nAS.ts &lt;- ts(AS$Shipments,start=c(1985,1), end=c(1989,4),freq=4)\n\nAS.ts\n\n\n     Qtr1 Qtr2 Qtr3 Qtr4\n1985 4009 4321 4224 3944\n1986 4123 4522 4657 4030\n1987 4493 4806 4551 4485\n1988 4595 4799 4417 4258\n1989 4245 4900 4585 4533\n\n\nCode\n#part a)\n#plot the original time series\nplot(AS.ts, xlab=\"Time\", ylab=\"Shipments\", bty=\"l\",xlim=c(1985,1989), ylim=c(3500,5500))\n\n#part b)\n#create centered and trailing moving averages\nma.centered &lt;- rollmean(AS.ts,k=4,align=\"center\")  #order is window size\nma.centered \n\n\n        Qtr1    Qtr2    Qtr3    Qtr4\n1985         4124.50 4153.00 4203.25\n1986 4311.50 4333.00 4425.50 4496.50\n1987 4470.00 4583.75 4609.25 4607.50\n1988 4574.00 4517.25 4429.75 4455.00\n1989 4497.00 4565.75                \n\n\nCode\nma.trailing &lt;- rollmean(AS.ts,k=4,align=\"right\") \nma.trailing\n\n\n        Qtr1    Qtr2    Qtr3    Qtr4\n1985                         4124.50\n1986 4153.00 4203.25 4311.50 4333.00\n1987 4425.50 4496.50 4470.00 4583.75\n1988 4609.25 4607.50 4574.00 4517.25\n1989 4429.75 4455.00 4497.00 4565.75\n\n\nCode\n# add centered moving average line\nlines(ma.centered,lwd=2,lty=2, col=\"red\")\n\n#add trailing moving average line\nlines(ma.trailing,lwd=2,lty=3, col=\"blue\")\nlegend(1987,5500, c(\"Shipments\",\"Centered Moving Average\"), lty=c(1,1))\n\n\n\n\n\n\n\n\n\nCode\n#part c)\n#Make training and validation sets\n#define validation period\nnValid &lt;- 4\n#define training period\nnTrain &lt;- length(AS.ts) - nValid\n#define training set\ntrain.ts &lt;- window(AS.ts, start=c(1985,1), end=c(1985,nTrain))\n#define validation set\nvalid.ts &lt;- window(AS.ts, start=c(1985,nTrain+1), end=c(1985,nTrain+nValid))\n\ntrain.ts\n\n\n     Qtr1 Qtr2 Qtr3 Qtr4\n1985 4009 4321 4224 3944\n1986 4123 4522 4657 4030\n1987 4493 4806 4551 4485\n1988 4595 4799 4417 4258\n\n\nCode\nvalid.ts\n\n\n     Qtr1 Qtr2 Qtr3 Qtr4\n1989 4245 4900 4585 4533\n\n\nCode\n#part d)\n#Do the smoothing\n#fit a smoothing model using ets() function. You could use ses(), holt(), or hw() depending on your time series characteristics\nshipment &lt;- ets(train.ts, model=\"AAA\") #alternatively you could fit ZMA or ZAM or ZMM\n#do the forecast based on the fitted model\nshipment.forecast &lt;- forecast(shipment,h=nValid,level=0)\n\nshipment.forecast\n\n\n        Point Forecast     Lo 0     Hi 0\n1989 Q1       4372.536 4372.536 4372.536\n1989 Q2       4563.806 4563.806 4563.806\n1989 Q3       4336.842 4336.842 4336.842\n1989 Q4       3882.621 3882.621 3882.621\n\n\nCode\n#calculate the accuracy on validation data\naccuracy(shipment.forecast, valid.ts)\n\n\n                    ME     RMSE      MAE        MPE     MAPE      MASE\nTraining set -36.01662 143.4371 102.2836 -0.8382982 2.304923 0.4872583\nTest set     276.79877 391.7486 340.5669  5.9041901 7.406385 1.6223912\n                   ACF1 Theil's U\nTraining set -0.1644880        NA\nTest set     -0.1184664   1.01571\n\n\nCode\n#the output of the accuracy() shows you the metrics on both training data and validation data. To assess the performance of your model without any bias, you should always look at validation data (unseen data).\n\n\n\n#part e)\n#plot\n#par(mfrow =c(2,1))\n#plot the forecast for validation period\nplot(shipment.forecast, xlab=\"Time\", ylab=\"Shipments\", bty=\"l\",xlim=c(1985,1990), ylim=c(3500,5500))\n\n#plot the actual data for validation period\nlines(valid.ts)\n\n#Plot the fitted values for training period\nlines(shipment.forecast$fitted,lwd=2,col=\"blue\")\n\n\n\n\n\n\n\n\n\nCode\n#shipment.forecast$fitted: this gives you the fitted values on the training data\n\n#part f)\n#plot the residuals of the training data\nplot(shipment.forecast$residuals, xlab=\"Time\", ylab=\"Shipments\", bty=\"l\",xlim=c(1985,1989.8),\n     ylim=c(0,0.1)) #multiplitive errors residuals are (real value / fitted values) - 1.\n\n\n\n\n\n\n\n\n\nCode\n#shipment.forecast$residuals: this gives you the residuals on the training data\n::: column-margin There was a small error in the provided code. The shipment.forecast &lt;- forecast(hwin,h=nValid,level=0) should be replaced with shipment.forecast &lt;- forecast(shipment,h=nValid,level=0)\nCode\n# Load the data\nsupermarket_data &lt;- read_excel(\"data/SupermarketSales.xlsx\")\n\n# plot the timeseries\nplot.ts(supermarket_data$demand)",
    "crumbs": [
      "Tutorials",
      "Tutorial 2"
    ]
  },
  {
    "objectID": "tutorial2.html#section",
    "href": "tutorial2.html#section",
    "title": "Tutorial week 2",
    "section": "1.2",
    "text": "1.2\nPrepare and clean the data as necessary to ensure accuracy for analysis.\na few notes: - there are a few missing observation dates (missing data) - there are negative values. Lets suppose they should be removed. - there are outliers, lets remove those as well\nNow we end up with much missing (“NA”) data. We should also curve-fit them\n\n\nCode\n# lets start by converting dates to a machine-readable date format\nsupermarket_data &lt;- supermarket_data %&gt;%\n  mutate(date = as.Date(as.character(date), format = \"%Y%m%d\"))\n\n# Now lets create a sequence of dates with the missing dates\nall_dates &lt;- data.frame(date = seq(min(supermarket_data$date), max(supermarket_data$date), by = \"day\"))\n\n# Join the two dataframes and introduce \"NA\" values on missing dates\ndata &lt;- all_dates %&gt;%\n  left_join(supermarket_data, by = \"date\")\n\n# Change any negative value to \"NA\"\ndata &lt;- data %&gt;%\n  mutate(demand = ifelse(demand &lt; 0, NA, demand))\n\nplot_ly(data, x = ~date, y = ~demand, type = 'scatter', mode = 'lines') # nice interactive plot",
    "crumbs": [
      "Tutorials",
      "Tutorial 2"
    ]
  },
  {
    "objectID": "tutorial2.html#section-1",
    "href": "tutorial2.html#section-1",
    "title": "Tutorial week 2",
    "section": "1.3",
    "text": "1.3\nSplit the data into training and validation sets. What proportion of the data would be reasonable for each set based on the characteristics of the time series?\n**In class a default of 80/20 or 70/30 was discussed. As there are 4 distinct periods, the last one could be used as validation set. (however, the demand in 2021 seems particularly weak!)\n§",
    "crumbs": [
      "Tutorials",
      "Tutorial 2"
    ]
  },
  {
    "objectID": "assignment1.html#forecasting",
    "href": "assignment1.html#forecasting",
    "title": "Assignment 1",
    "section": "Forecasting",
    "text": "Forecasting\n4A – Consider a part of your dataset including 3 products/services: For each of these 3 product/service, apply at least 3 relevant forecasting techniques/methods (please note that you need to justify why you applied these 3 methods among many others). For each product/service, evaluate these methods based on their accuracy (Note that the naïve, seasonal naïve, and moving average methods are not counted as these methods.).\nLets forecast sales for the three most sold sub-categories:\n\n\nCode\n# Find top 3 most sold product names\ntop_3_subcategories &lt;- top_categories$`Sub-Category`[0:3]\n\n\n\n\n# Filter the data for  top 3 products\ntop_3_data &lt;- data %&gt;% filter(`Sub-Category` %in% top_3_subcategories)\n\n# calculate sales per month\ntop_3_data &lt;- top_3_data %&gt;%\n  mutate(Month = floor_date(`Order Date`, unit = \"month\"))\n\n# Aggregate data by month for each product\ntop_3_data_aggregated &lt;- top_3_data %&gt;%\n  group_by(Month, `Sub-Category`) %&gt;%\n  summarise(Sales_Count = n(), .groups = 'drop')\n\n# Create a time series object for each product\nts_data &lt;- top_3_data_aggregated %&gt;%\n  pivot_wider(names_from = `Sub-Category`, values_from = Sales_Count, values_fill = 0) %&gt;%\n  select(-Month) %&gt;%\n  as.matrix()\n\n# Create a time series object\nts_data &lt;- ts(ts_data, start = c(2014, 1), end = c(2017, 12), frequency = 12)\n\n# Forecasting\n# ARIMA\n# arima_forecasts &lt;- lapply(1:ncol(ts_data), function(i) forecast(auto.arima(ts_data[, i]), h = 12))\n\n# Exponential Smoothing\n# ets_forecasts &lt;- lapply(1:ncol(ts_data), function(i) forecast(ets(ts_data[, i]), h = 12))\n\n\n# Plot the forecasts\n# for (i in 1:3) {\n#   plot(arima_forecasts[[i]], main = top_3_subcategories[i])\n#   plot(ets_forecasts[[i]], main = top_3_subcategories[i])\n# }",
    "crumbs": [
      "Assignments",
      "Assignment 1"
    ]
  }
]